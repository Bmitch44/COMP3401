{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data\n",
    "Load the dataset ( train.csv ) into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_46</th>\n",
       "      <th>Feature_47</th>\n",
       "      <th>Feature_48</th>\n",
       "      <th>Feature_49</th>\n",
       "      <th>Feature_50</th>\n",
       "      <th>Feature_51</th>\n",
       "      <th>Feature_52</th>\n",
       "      <th>Feature_53</th>\n",
       "      <th>Feature_54</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3289</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>240</td>\n",
       "      <td>93</td>\n",
       "      <td>1708</td>\n",
       "      <td>205</td>\n",
       "      <td>196</td>\n",
       "      <td>122</td>\n",
       "      <td>2598</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>134</td>\n",
       "      <td>27</td>\n",
       "      <td>1243</td>\n",
       "      <td>206</td>\n",
       "      <td>200</td>\n",
       "      <td>127</td>\n",
       "      <td>1140</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3037</td>\n",
       "      <td>185</td>\n",
       "      <td>9</td>\n",
       "      <td>127</td>\n",
       "      <td>10</td>\n",
       "      <td>6462</td>\n",
       "      <td>222</td>\n",
       "      <td>246</td>\n",
       "      <td>158</td>\n",
       "      <td>3037</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3113</td>\n",
       "      <td>203</td>\n",
       "      <td>13</td>\n",
       "      <td>190</td>\n",
       "      <td>22</td>\n",
       "      <td>2125</td>\n",
       "      <td>213</td>\n",
       "      <td>251</td>\n",
       "      <td>171</td>\n",
       "      <td>730</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3128</td>\n",
       "      <td>346</td>\n",
       "      <td>9</td>\n",
       "      <td>120</td>\n",
       "      <td>36</td>\n",
       "      <td>552</td>\n",
       "      <td>203</td>\n",
       "      <td>226</td>\n",
       "      <td>161</td>\n",
       "      <td>924</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0       3289         22         19        240         93       1708   \n",
       "1       2963         21         18        134         27       1243   \n",
       "2       3037        185          9        127         10       6462   \n",
       "3       3113        203         13        190         22       2125   \n",
       "4       3128        346          9        120         36        552   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_46  Feature_47  \\\n",
       "0        205        196        122        2598  ...           0           1   \n",
       "1        206        200        127        1140  ...           0           0   \n",
       "2        222        246        158        3037  ...           0           0   \n",
       "3        213        251        171         730  ...           1           0   \n",
       "4        203        226        161         924  ...           0           0   \n",
       "\n",
       "   Feature_48  Feature_49  Feature_50  Feature_51  Feature_52  Feature_53  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   Feature_54  Target  \n",
       "0           0       1  \n",
       "1           0       1  \n",
       "2           0       2  \n",
       "3           0       2  \n",
       "4           0       1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('a4-data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split the Data into Features (X) and Target (Y)\n",
    "Divide the dataset into features (X) and the target variable (Y). Markdown explanation: Explain the rationale behind separating features from the target in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((464809, 54), (464809,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Splitting\n",
    "Split the data into training and test sets to evaluate the model's performance. Markdown explanation: Describe the importance of having training and test datasets in model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((325366, 54), (139443, 54), (325366,), (139443,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the Neural Network Model\n",
    "Design your neural network using TensorFlow and Keras, choosing appropriate activation functions. Markdown explanation: Detail your model's architecture, including layer types, sizes, and activation functions used. Also, (IMPORTANT) explain why you are choosing the activations functions you picked. Explain, if you ﬁnd the performance of the neural network improves by changing the layers or the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(units=32, activation='relu'),\n",
    "        Dense(units=16, activation='relu'),\n",
    "        Dense(units=(y_train.nunique()+1) , activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "Train your neural network on the training set. Markdown explanation: Discuss the model training process, highlighting your choices of optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356us/step - accuracy: 0.4761 - loss: 5.7202\n",
      "Epoch 2/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 343us/step - accuracy: 0.4881 - loss: 1.2032\n",
      "Epoch 3/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340us/step - accuracy: 0.4902 - loss: 1.2024\n",
      "Epoch 4/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 0.4880 - loss: 1.2033\n",
      "Epoch 5/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 395us/step - accuracy: 0.4873 - loss: 1.2025\n",
      "Epoch 6/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340us/step - accuracy: 0.4894 - loss: 1.2027\n",
      "Epoch 7/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342us/step - accuracy: 0.4880 - loss: 1.2025\n",
      "Epoch 8/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 0.4868 - loss: 1.2039\n",
      "Epoch 9/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341us/step - accuracy: 0.4878 - loss: 1.2055\n",
      "Epoch 10/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 0.4877 - loss: 1.2043\n",
      "Epoch 11/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 0.4884 - loss: 1.2030\n",
      "Epoch 12/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362us/step - accuracy: 0.4883 - loss: 1.2044\n",
      "Epoch 13/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 411us/step - accuracy: 0.4887 - loss: 1.2026\n",
      "Epoch 14/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 0.4884 - loss: 1.2048\n",
      "Epoch 15/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 338us/step - accuracy: 0.4887 - loss: 1.2046\n",
      "Epoch 16/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 440us/step - accuracy: 0.4879 - loss: 1.2045\n",
      "Epoch 17/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374us/step - accuracy: 0.4889 - loss: 1.2041\n",
      "Epoch 18/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 0.4890 - loss: 1.2010\n",
      "Epoch 19/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341us/step - accuracy: 0.4877 - loss: 1.2052\n",
      "Epoch 20/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 392us/step - accuracy: 0.4883 - loss: 1.2061\n",
      "Epoch 21/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 359us/step - accuracy: 0.4886 - loss: 1.2048\n",
      "Epoch 22/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 361us/step - accuracy: 0.4873 - loss: 1.2056\n",
      "Epoch 23/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 400us/step - accuracy: 0.4890 - loss: 1.2056\n",
      "Epoch 24/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 412us/step - accuracy: 0.4879 - loss: 1.2047\n",
      "Epoch 25/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 0.4883 - loss: 1.2052\n",
      "Epoch 26/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333us/step - accuracy: 0.4893 - loss: 1.2029\n",
      "Epoch 27/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 0.4890 - loss: 1.2046\n",
      "Epoch 28/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 337us/step - accuracy: 0.4887 - loss: 1.2035\n",
      "Epoch 29/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 327us/step - accuracy: 0.4877 - loss: 1.2044\n",
      "Epoch 30/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 335us/step - accuracy: 0.4875 - loss: 1.2038\n",
      "Epoch 31/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340us/step - accuracy: 0.4893 - loss: 1.2048\n",
      "Epoch 32/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 397us/step - accuracy: 0.4877 - loss: 1.2049\n",
      "Epoch 33/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419us/step - accuracy: 0.4903 - loss: 1.2035\n",
      "Epoch 34/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 434us/step - accuracy: 0.4899 - loss: 1.2049\n",
      "Epoch 35/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 413us/step - accuracy: 0.4871 - loss: 1.2058\n",
      "Epoch 36/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336us/step - accuracy: 0.4892 - loss: 1.2052\n",
      "Epoch 37/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376us/step - accuracy: 0.4883 - loss: 1.2036\n",
      "Epoch 38/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 399us/step - accuracy: 0.4876 - loss: 1.2014\n",
      "Epoch 39/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 0.4884 - loss: 1.2039\n",
      "Epoch 40/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 360us/step - accuracy: 0.4889 - loss: 1.2032\n",
      "Epoch 41/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 363us/step - accuracy: 0.4879 - loss: 1.2051\n",
      "Epoch 42/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 0.4884 - loss: 1.2040\n",
      "Epoch 43/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 0.4878 - loss: 1.2057\n",
      "Epoch 44/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 389us/step - accuracy: 0.4867 - loss: 1.2086\n",
      "Epoch 45/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 493us/step - accuracy: 0.4885 - loss: 1.2032\n",
      "Epoch 46/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 346us/step - accuracy: 0.4891 - loss: 1.2029\n",
      "Epoch 47/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334us/step - accuracy: 0.4879 - loss: 1.2065\n",
      "Epoch 48/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 329us/step - accuracy: 0.4881 - loss: 1.2047\n",
      "Epoch 49/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 384us/step - accuracy: 0.4879 - loss: 1.2058\n",
      "Epoch 50/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 0.4879 - loss: 1.2052\n",
      "Epoch 51/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377us/step - accuracy: 0.4883 - loss: 1.2056\n",
      "Epoch 52/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333us/step - accuracy: 0.4884 - loss: 1.2042\n",
      "Epoch 53/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 353us/step - accuracy: 0.4874 - loss: 1.2020\n",
      "Epoch 54/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 0.4891 - loss: 1.2024\n",
      "Epoch 55/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 0.4874 - loss: 1.2055\n",
      "Epoch 56/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341us/step - accuracy: 0.4886 - loss: 1.2040\n",
      "Epoch 57/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 0.4876 - loss: 1.2061\n",
      "Epoch 58/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 391us/step - accuracy: 0.4880 - loss: 1.2038\n",
      "Epoch 59/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 337us/step - accuracy: 0.4872 - loss: 1.2066\n",
      "Epoch 60/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 0.4870 - loss: 1.2074\n",
      "Epoch 61/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 330us/step - accuracy: 0.4876 - loss: 1.2058\n",
      "Epoch 62/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 336us/step - accuracy: 0.4886 - loss: 1.2053\n",
      "Epoch 63/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 334us/step - accuracy: 0.4869 - loss: 1.2067\n",
      "Epoch 64/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378us/step - accuracy: 0.4897 - loss: 1.2022\n",
      "Epoch 65/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 0.4871 - loss: 1.2035\n",
      "Epoch 66/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383us/step - accuracy: 0.4891 - loss: 1.2031\n",
      "Epoch 67/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 345us/step - accuracy: 0.4874 - loss: 1.2063\n",
      "Epoch 68/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379us/step - accuracy: 0.4878 - loss: 1.2058\n",
      "Epoch 69/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 388us/step - accuracy: 0.4892 - loss: 1.2041\n",
      "Epoch 70/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 358us/step - accuracy: 0.4883 - loss: 1.2039\n",
      "Epoch 71/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 0.4869 - loss: 1.2053\n",
      "Epoch 72/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 0.4859 - loss: 1.2071\n",
      "Epoch 73/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 333us/step - accuracy: 0.4889 - loss: 1.2036\n",
      "Epoch 74/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 0.4869 - loss: 1.2032\n",
      "Epoch 75/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344us/step - accuracy: 0.4879 - loss: 1.2062\n",
      "Epoch 76/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 351us/step - accuracy: 0.4882 - loss: 1.2046\n",
      "Epoch 77/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 0.4873 - loss: 1.2041\n",
      "Epoch 78/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 352us/step - accuracy: 0.4876 - loss: 1.2058\n",
      "Epoch 79/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354us/step - accuracy: 0.4879 - loss: 1.2020\n",
      "Epoch 80/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 355us/step - accuracy: 0.4870 - loss: 1.2047\n",
      "Epoch 81/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 0.4861 - loss: 1.2054\n",
      "Epoch 82/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 347us/step - accuracy: 0.4890 - loss: 1.2045\n",
      "Epoch 83/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 345us/step - accuracy: 0.4897 - loss: 1.2032\n",
      "Epoch 84/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 348us/step - accuracy: 0.4866 - loss: 1.2064\n",
      "Epoch 85/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 349us/step - accuracy: 0.4889 - loss: 1.2011\n",
      "Epoch 86/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 420us/step - accuracy: 0.4879 - loss: 1.2031\n",
      "Epoch 87/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 367us/step - accuracy: 0.4891 - loss: 1.2034\n",
      "Epoch 88/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 382us/step - accuracy: 0.4871 - loss: 1.2051\n",
      "Epoch 89/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 377us/step - accuracy: 0.4877 - loss: 1.2054\n",
      "Epoch 90/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381us/step - accuracy: 0.4887 - loss: 1.2065\n",
      "Epoch 91/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 379us/step - accuracy: 0.4876 - loss: 1.2056\n",
      "Epoch 92/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365us/step - accuracy: 0.4870 - loss: 1.2072\n",
      "Epoch 93/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350us/step - accuracy: 0.4862 - loss: 1.2042\n",
      "Epoch 94/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357us/step - accuracy: 0.4895 - loss: 1.2024\n",
      "Epoch 95/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 366us/step - accuracy: 0.4888 - loss: 1.2029\n",
      "Epoch 96/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 382us/step - accuracy: 0.4860 - loss: 1.2042\n",
      "Epoch 97/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381us/step - accuracy: 0.4882 - loss: 1.2057\n",
      "Epoch 98/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 395us/step - accuracy: 0.4899 - loss: 1.2028\n",
      "Epoch 99/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365us/step - accuracy: 0.4891 - loss: 1.2047\n",
      "Epoch 100/100\n",
      "\u001b[1m10168/10168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 393us/step - accuracy: 0.4892 - loss: 1.2028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2da37f760>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation\n",
    "Evaluate your model's performance on the test set. Markdown explanation: Explain how model evaluation is performed and what metrics can be used to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4358/4358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306us/step - accuracy: 0.4876 - loss: 1.2052\n",
      "Loss: 1.2071019411087036, Accuracy: 0.4870520532131195\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions\n",
    "Use your trained model to make predictions on the test set. See test.csv . This ﬁle only contains the features and not the target. Markdown explanation: Outline the process of making predictions with a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_45</th>\n",
       "      <th>Feature_46</th>\n",
       "      <th>Feature_47</th>\n",
       "      <th>Feature_48</th>\n",
       "      <th>Feature_49</th>\n",
       "      <th>Feature_50</th>\n",
       "      <th>Feature_51</th>\n",
       "      <th>Feature_52</th>\n",
       "      <th>Feature_53</th>\n",
       "      <th>Feature_54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3351</td>\n",
       "      <td>206</td>\n",
       "      <td>27</td>\n",
       "      <td>726</td>\n",
       "      <td>124</td>\n",
       "      <td>3813</td>\n",
       "      <td>192</td>\n",
       "      <td>252</td>\n",
       "      <td>180</td>\n",
       "      <td>2271</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2732</td>\n",
       "      <td>129</td>\n",
       "      <td>7</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1082</td>\n",
       "      <td>231</td>\n",
       "      <td>236</td>\n",
       "      <td>137</td>\n",
       "      <td>912</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2572</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>201</td>\n",
       "      <td>25</td>\n",
       "      <td>957</td>\n",
       "      <td>216</td>\n",
       "      <td>222</td>\n",
       "      <td>142</td>\n",
       "      <td>2191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2824</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>417</td>\n",
       "      <td>39</td>\n",
       "      <td>3223</td>\n",
       "      <td>233</td>\n",
       "      <td>214</td>\n",
       "      <td>110</td>\n",
       "      <td>6478</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2529</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>1092</td>\n",
       "      <td>227</td>\n",
       "      <td>231</td>\n",
       "      <td>139</td>\n",
       "      <td>4983</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0       3351        206         27        726        124       3813   \n",
       "1       2732        129          7        212          1       1082   \n",
       "2       2572         24          9        201         25        957   \n",
       "3       2824         69         13        417         39       3223   \n",
       "4       2529         84          5        120          9       1092   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_45  Feature_46  \\\n",
       "0        192        252        180        2271  ...           0           0   \n",
       "1        231        236        137         912  ...           0           0   \n",
       "2        216        222        142        2191  ...           0           0   \n",
       "3        233        214        110        6478  ...           0           0   \n",
       "4        227        231        139        4983  ...           0           0   \n",
       "\n",
       "   Feature_47  Feature_48  Feature_49  Feature_50  Feature_51  Feature_52  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   Feature_53  Feature_54  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('a4-data/test.csv')\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_set)\n\u001b[1;32m      4\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m predicted_classes\u001b[38;5;241m.\u001b[39mnunique()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(test_set)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Submission File\n",
    "Create a submission ﬁle with your predictions, formatied similarly to sample_submission.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Target': predicted_classes})\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Submission\n",
    "Submit your Jupyter notebook and the predictions CSV ﬁle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp3401",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
